{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, CharacterEmbeddings, FlairEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "import torch\n",
    "flair.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 10:19:27,356 Reading data from ../../data\n",
      "2021-02-09 10:19:27,357 Train: ../../data/train.conll\n",
      "2021-02-09 10:19:27,357 Dev: ../../data/dev.conll\n",
      "2021-02-09 10:19:27,358 Test: ../../data/test.conll\n",
      "Corpus: 6544 train + 728 dev + 1818 test sentences\n"
     ]
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "corpus: Corpus = ColumnCorpus(\n",
    "    \"../../data/\", column_format={0:'text', 1:'ner'},\n",
    "    train_file='train.conll', dev_file='dev.conll', test_file='test.conll',\n",
    ")\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 14 tags: <unk>, O, B-BOOK, I-BOOK, B-SINGER, I-SINGER, B-COMPOSER, I-COMPOSER, B-FILM, B-SONG, I-SONG, I-FILM, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "    CharacterEmbeddings()\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 10:20:35,698 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:20:35,699 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): CharacterEmbeddings(\n",
      "      (char_embedding): Embedding(275, 25)\n",
      "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (rnn): LSTM(50, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=14, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-02-09 10:20:35,699 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:20:35,699 Corpus: \"Corpus: 6544 train + 728 dev + 1818 test sentences\"\n",
      "2021-02-09 10:20:35,700 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:20:35,700 Parameters:\n",
      "2021-02-09 10:20:35,701  - learning_rate: \"0.1\"\n",
      "2021-02-09 10:20:35,701  - mini_batch_size: \"32\"\n",
      "2021-02-09 10:20:35,701  - patience: \"3\"\n",
      "2021-02-09 10:20:35,702  - anneal_factor: \"0.5\"\n",
      "2021-02-09 10:20:35,702  - max_epochs: \"20\"\n",
      "2021-02-09 10:20:35,702  - shuffle: \"True\"\n",
      "2021-02-09 10:20:35,703  - train_with_dev: \"False\"\n",
      "2021-02-09 10:20:35,703  - batch_growth_annealing: \"False\"\n",
      "2021-02-09 10:20:35,703 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:20:35,704 Model training base path: \"models/baseline-charembeddings\"\n",
      "2021-02-09 10:20:35,704 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:20:35,704 Device: cpu\n",
      "2021-02-09 10:20:35,705 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:20:35,705 Embeddings storage mode: cpu\n",
      "2021-02-09 10:20:35,707 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:20:39,178 epoch 1 - iter 20/205 - loss 8.99058440 - samples/sec: 184.53 - lr: 0.100000\n",
      "2021-02-09 10:20:42,518 epoch 1 - iter 40/205 - loss 7.89145349 - samples/sec: 191.65 - lr: 0.100000\n",
      "2021-02-09 10:20:45,883 epoch 1 - iter 60/205 - loss 7.19513186 - samples/sec: 190.31 - lr: 0.100000\n",
      "2021-02-09 10:20:49,167 epoch 1 - iter 80/205 - loss 6.68660010 - samples/sec: 194.94 - lr: 0.100000\n",
      "2021-02-09 10:20:52,591 epoch 1 - iter 100/205 - loss 6.31550881 - samples/sec: 187.02 - lr: 0.100000\n",
      "2021-02-09 10:20:56,045 epoch 1 - iter 120/205 - loss 6.00512199 - samples/sec: 185.41 - lr: 0.100000\n",
      "2021-02-09 10:20:59,586 epoch 1 - iter 140/205 - loss 5.72861862 - samples/sec: 180.83 - lr: 0.100000\n",
      "2021-02-09 10:21:03,082 epoch 1 - iter 160/205 - loss 5.48126204 - samples/sec: 183.13 - lr: 0.100000\n",
      "2021-02-09 10:21:06,486 epoch 1 - iter 180/205 - loss 5.28888387 - samples/sec: 188.12 - lr: 0.100000\n",
      "2021-02-09 10:21:09,858 epoch 1 - iter 200/205 - loss 5.10812237 - samples/sec: 189.84 - lr: 0.100000\n",
      "2021-02-09 10:21:10,627 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:21:10,628 EPOCH 1 done: loss 5.0645 - lr 0.1000000\n",
      "2021-02-09 10:21:11,865 DEV : loss 3.430722713470459 - score 0.3232\n",
      "2021-02-09 10:21:11,871 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:21:11,876 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:21:15,476 epoch 2 - iter 20/205 - loss 3.45657599 - samples/sec: 177.87 - lr: 0.100000\n",
      "2021-02-09 10:21:18,887 epoch 2 - iter 40/205 - loss 3.26261945 - samples/sec: 187.68 - lr: 0.100000\n",
      "2021-02-09 10:21:22,462 epoch 2 - iter 60/205 - loss 3.17858687 - samples/sec: 179.13 - lr: 0.100000\n",
      "2021-02-09 10:21:25,985 epoch 2 - iter 80/205 - loss 3.14393540 - samples/sec: 181.76 - lr: 0.100000\n",
      "2021-02-09 10:21:29,507 epoch 2 - iter 100/205 - loss 3.06048259 - samples/sec: 181.78 - lr: 0.100000\n",
      "2021-02-09 10:21:32,974 epoch 2 - iter 120/205 - loss 2.99853292 - samples/sec: 184.68 - lr: 0.100000\n",
      "2021-02-09 10:21:36,406 epoch 2 - iter 140/205 - loss 2.95185845 - samples/sec: 186.55 - lr: 0.100000\n",
      "2021-02-09 10:21:39,821 epoch 2 - iter 160/205 - loss 2.91985094 - samples/sec: 187.52 - lr: 0.100000\n",
      "2021-02-09 10:21:43,468 epoch 2 - iter 180/205 - loss 2.90410845 - samples/sec: 175.54 - lr: 0.100000\n",
      "2021-02-09 10:21:46,975 epoch 2 - iter 200/205 - loss 2.88444984 - samples/sec: 182.57 - lr: 0.100000\n",
      "2021-02-09 10:21:47,784 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:21:47,785 EPOCH 2 done: loss 2.8761 - lr 0.1000000\n",
      "2021-02-09 10:21:48,884 DEV : loss 2.458090305328369 - score 0.4383\n",
      "2021-02-09 10:21:48,889 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:21:48,894 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:21:52,260 epoch 3 - iter 20/205 - loss 2.55565366 - samples/sec: 190.22 - lr: 0.100000\n",
      "2021-02-09 10:21:55,742 epoch 3 - iter 40/205 - loss 2.50600935 - samples/sec: 183.90 - lr: 0.100000\n",
      "2021-02-09 10:21:59,287 epoch 3 - iter 60/205 - loss 2.47855862 - samples/sec: 180.60 - lr: 0.100000\n",
      "2021-02-09 10:22:02,832 epoch 3 - iter 80/205 - loss 2.43568646 - samples/sec: 180.62 - lr: 0.100000\n",
      "2021-02-09 10:22:06,336 epoch 3 - iter 100/205 - loss 2.39700896 - samples/sec: 182.74 - lr: 0.100000\n",
      "2021-02-09 10:22:09,843 epoch 3 - iter 120/205 - loss 2.37223358 - samples/sec: 182.55 - lr: 0.100000\n",
      "2021-02-09 10:22:13,464 epoch 3 - iter 140/205 - loss 2.34991523 - samples/sec: 176.82 - lr: 0.100000\n",
      "2021-02-09 10:22:16,961 epoch 3 - iter 160/205 - loss 2.31713697 - samples/sec: 183.10 - lr: 0.100000\n",
      "2021-02-09 10:22:20,458 epoch 3 - iter 180/205 - loss 2.29584321 - samples/sec: 183.13 - lr: 0.100000\n",
      "2021-02-09 10:22:23,933 epoch 3 - iter 200/205 - loss 2.26593324 - samples/sec: 184.27 - lr: 0.100000\n",
      "2021-02-09 10:22:24,722 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:22:24,722 EPOCH 3 done: loss 2.2623 - lr 0.1000000\n",
      "2021-02-09 10:22:25,829 DEV : loss 1.91990327835083 - score 0.5021\n",
      "2021-02-09 10:22:25,835 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:22:25,839 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:22:29,301 epoch 4 - iter 20/205 - loss 2.01941869 - samples/sec: 184.99 - lr: 0.100000\n",
      "2021-02-09 10:22:32,840 epoch 4 - iter 40/205 - loss 2.01401297 - samples/sec: 180.89 - lr: 0.100000\n",
      "2021-02-09 10:22:36,335 epoch 4 - iter 60/205 - loss 1.95443663 - samples/sec: 183.22 - lr: 0.100000\n",
      "2021-02-09 10:22:39,784 epoch 4 - iter 80/205 - loss 1.93062230 - samples/sec: 185.64 - lr: 0.100000\n",
      "2021-02-09 10:22:43,308 epoch 4 - iter 100/205 - loss 1.90482473 - samples/sec: 181.70 - lr: 0.100000\n",
      "2021-02-09 10:22:46,871 epoch 4 - iter 120/205 - loss 1.90841473 - samples/sec: 179.72 - lr: 0.100000\n",
      "2021-02-09 10:22:50,492 epoch 4 - iter 140/205 - loss 1.89648237 - samples/sec: 176.84 - lr: 0.100000\n",
      "2021-02-09 10:22:53,997 epoch 4 - iter 160/205 - loss 1.88708985 - samples/sec: 182.65 - lr: 0.100000\n",
      "2021-02-09 10:22:57,551 epoch 4 - iter 180/205 - loss 1.87260656 - samples/sec: 180.19 - lr: 0.100000\n",
      "2021-02-09 10:23:01,073 epoch 4 - iter 200/205 - loss 1.87018862 - samples/sec: 181.79 - lr: 0.100000\n",
      "2021-02-09 10:23:01,891 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:23:01,892 EPOCH 4 done: loss 1.8699 - lr 0.1000000\n",
      "2021-02-09 10:23:02,997 DEV : loss 1.6068568229675293 - score 0.5673\n",
      "2021-02-09 10:23:03,003 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:23:03,008 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:23:06,418 epoch 5 - iter 20/205 - loss 1.65890073 - samples/sec: 187.77 - lr: 0.100000\n",
      "2021-02-09 10:23:09,880 epoch 5 - iter 40/205 - loss 1.66099114 - samples/sec: 184.94 - lr: 0.100000\n",
      "2021-02-09 10:23:13,368 epoch 5 - iter 60/205 - loss 1.66344435 - samples/sec: 183.58 - lr: 0.100000\n",
      "2021-02-09 10:23:16,980 epoch 5 - iter 80/205 - loss 1.66635181 - samples/sec: 177.25 - lr: 0.100000\n",
      "2021-02-09 10:23:20,449 epoch 5 - iter 100/205 - loss 1.66346793 - samples/sec: 184.57 - lr: 0.100000\n",
      "2021-02-09 10:23:23,989 epoch 5 - iter 120/205 - loss 1.66383658 - samples/sec: 180.88 - lr: 0.100000\n",
      "2021-02-09 10:23:27,395 epoch 5 - iter 140/205 - loss 1.66079532 - samples/sec: 187.96 - lr: 0.100000\n",
      "2021-02-09 10:23:30,820 epoch 5 - iter 160/205 - loss 1.64912126 - samples/sec: 186.97 - lr: 0.100000\n",
      "2021-02-09 10:23:34,409 epoch 5 - iter 180/205 - loss 1.65258738 - samples/sec: 178.42 - lr: 0.100000\n",
      "2021-02-09 10:23:37,883 epoch 5 - iter 200/205 - loss 1.64402098 - samples/sec: 184.33 - lr: 0.100000\n",
      "2021-02-09 10:23:38,757 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:23:38,757 EPOCH 5 done: loss 1.6421 - lr 0.1000000\n",
      "2021-02-09 10:23:39,867 DEV : loss 1.407844066619873 - score 0.568\n",
      "2021-02-09 10:23:39,872 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:23:39,879 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:23:43,406 epoch 6 - iter 20/205 - loss 1.56753737 - samples/sec: 181.58 - lr: 0.100000\n",
      "2021-02-09 10:23:47,022 epoch 6 - iter 40/205 - loss 1.58766403 - samples/sec: 177.07 - lr: 0.100000\n",
      "2021-02-09 10:23:50,499 epoch 6 - iter 60/205 - loss 1.58375699 - samples/sec: 184.17 - lr: 0.100000\n",
      "2021-02-09 10:23:54,038 epoch 6 - iter 80/205 - loss 1.56358815 - samples/sec: 180.91 - lr: 0.100000\n",
      "2021-02-09 10:23:57,632 epoch 6 - iter 100/205 - loss 1.54986480 - samples/sec: 178.16 - lr: 0.100000\n",
      "2021-02-09 10:24:01,135 epoch 6 - iter 120/205 - loss 1.54319906 - samples/sec: 182.77 - lr: 0.100000\n",
      "2021-02-09 10:24:04,699 epoch 6 - iter 140/205 - loss 1.53914378 - samples/sec: 179.67 - lr: 0.100000\n",
      "2021-02-09 10:24:08,240 epoch 6 - iter 160/205 - loss 1.52458445 - samples/sec: 180.84 - lr: 0.100000\n",
      "2021-02-09 10:24:11,711 epoch 6 - iter 180/205 - loss 1.51234513 - samples/sec: 184.45 - lr: 0.100000\n",
      "2021-02-09 10:24:15,166 epoch 6 - iter 200/205 - loss 1.51368308 - samples/sec: 185.34 - lr: 0.100000\n",
      "2021-02-09 10:24:15,935 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:24:15,936 EPOCH 6 done: loss 1.5124 - lr 0.1000000\n",
      "2021-02-09 10:24:17,039 DEV : loss 1.329329252243042 - score 0.5851\n",
      "2021-02-09 10:24:17,044 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:24:17,049 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:24:20,579 epoch 7 - iter 20/205 - loss 1.44203483 - samples/sec: 181.41 - lr: 0.100000\n",
      "2021-02-09 10:24:24,162 epoch 7 - iter 40/205 - loss 1.47556864 - samples/sec: 178.68 - lr: 0.100000\n",
      "2021-02-09 10:24:27,748 epoch 7 - iter 60/205 - loss 1.44028251 - samples/sec: 178.57 - lr: 0.100000\n",
      "2021-02-09 10:24:31,275 epoch 7 - iter 80/205 - loss 1.44828333 - samples/sec: 181.54 - lr: 0.100000\n",
      "2021-02-09 10:24:34,830 epoch 7 - iter 100/205 - loss 1.45107697 - samples/sec: 180.12 - lr: 0.100000\n",
      "2021-02-09 10:24:38,283 epoch 7 - iter 120/205 - loss 1.45553617 - samples/sec: 185.45 - lr: 0.100000\n",
      "2021-02-09 10:24:41,788 epoch 7 - iter 140/205 - loss 1.45981599 - samples/sec: 182.64 - lr: 0.100000\n",
      "2021-02-09 10:24:45,485 epoch 7 - iter 160/205 - loss 1.45091046 - samples/sec: 173.22 - lr: 0.100000\n",
      "2021-02-09 10:24:48,971 epoch 7 - iter 180/205 - loss 1.44505725 - samples/sec: 183.65 - lr: 0.100000\n",
      "2021-02-09 10:24:52,595 epoch 7 - iter 200/205 - loss 1.44844459 - samples/sec: 176.69 - lr: 0.100000\n",
      "2021-02-09 10:24:53,404 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:24:53,405 EPOCH 7 done: loss 1.4488 - lr 0.1000000\n",
      "2021-02-09 10:24:54,549 DEV : loss 1.2993453741073608 - score 0.5769\n",
      "2021-02-09 10:24:54,554 BAD EPOCHS (no improvement): 1\n",
      "2021-02-09 10:24:54,555 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:24:58,159 epoch 8 - iter 20/205 - loss 1.42188279 - samples/sec: 177.61 - lr: 0.100000\n",
      "2021-02-09 10:25:01,755 epoch 8 - iter 40/205 - loss 1.38582191 - samples/sec: 178.08 - lr: 0.100000\n",
      "2021-02-09 10:25:05,295 epoch 8 - iter 60/205 - loss 1.38422118 - samples/sec: 180.86 - lr: 0.100000\n",
      "2021-02-09 10:25:08,842 epoch 8 - iter 80/205 - loss 1.37045533 - samples/sec: 180.57 - lr: 0.100000\n",
      "2021-02-09 10:25:12,338 epoch 8 - iter 100/205 - loss 1.37679804 - samples/sec: 183.14 - lr: 0.100000\n",
      "2021-02-09 10:25:15,976 epoch 8 - iter 120/205 - loss 1.39102606 - samples/sec: 176.01 - lr: 0.100000\n",
      "2021-02-09 10:25:19,475 epoch 8 - iter 140/205 - loss 1.38542640 - samples/sec: 182.97 - lr: 0.100000\n",
      "2021-02-09 10:25:22,921 epoch 8 - iter 160/205 - loss 1.38030114 - samples/sec: 185.81 - lr: 0.100000\n",
      "2021-02-09 10:25:26,566 epoch 8 - iter 180/205 - loss 1.38292892 - samples/sec: 175.67 - lr: 0.100000\n",
      "2021-02-09 10:25:30,007 epoch 8 - iter 200/205 - loss 1.38283411 - samples/sec: 186.09 - lr: 0.100000\n",
      "2021-02-09 10:25:30,834 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:25:30,835 EPOCH 8 done: loss 1.3830 - lr 0.1000000\n",
      "2021-02-09 10:25:31,950 DEV : loss 1.251154899597168 - score 0.5856\n",
      "2021-02-09 10:25:31,956 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:25:31,961 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:25:35,511 epoch 9 - iter 20/205 - loss 1.32742387 - samples/sec: 180.38 - lr: 0.100000\n",
      "2021-02-09 10:25:38,980 epoch 9 - iter 40/205 - loss 1.33924678 - samples/sec: 184.83 - lr: 0.100000\n",
      "2021-02-09 10:25:42,579 epoch 9 - iter 60/205 - loss 1.35442547 - samples/sec: 177.90 - lr: 0.100000\n",
      "2021-02-09 10:25:46,086 epoch 9 - iter 80/205 - loss 1.36722756 - samples/sec: 182.56 - lr: 0.100000\n",
      "2021-02-09 10:25:49,686 epoch 9 - iter 100/205 - loss 1.35635887 - samples/sec: 177.86 - lr: 0.100000\n",
      "2021-02-09 10:25:53,212 epoch 9 - iter 120/205 - loss 1.35795515 - samples/sec: 181.62 - lr: 0.100000\n",
      "2021-02-09 10:25:56,751 epoch 9 - iter 140/205 - loss 1.36048995 - samples/sec: 180.92 - lr: 0.100000\n",
      "2021-02-09 10:26:00,239 epoch 9 - iter 160/205 - loss 1.36206913 - samples/sec: 183.57 - lr: 0.100000\n",
      "2021-02-09 10:26:03,709 epoch 9 - iter 180/205 - loss 1.35431845 - samples/sec: 184.50 - lr: 0.100000\n",
      "2021-02-09 10:26:07,238 epoch 9 - iter 200/205 - loss 1.35456024 - samples/sec: 181.41 - lr: 0.100000\n",
      "2021-02-09 10:26:08,028 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:26:08,029 EPOCH 9 done: loss 1.3532 - lr 0.1000000\n",
      "2021-02-09 10:26:09,110 DEV : loss 1.2015000581741333 - score 0.5981\n",
      "2021-02-09 10:26:09,116 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:26:09,121 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:26:12,614 epoch 10 - iter 20/205 - loss 1.34104016 - samples/sec: 183.31 - lr: 0.100000\n",
      "2021-02-09 10:26:16,085 epoch 10 - iter 40/205 - loss 1.36121433 - samples/sec: 184.47 - lr: 0.100000\n",
      "2021-02-09 10:26:19,629 epoch 10 - iter 60/205 - loss 1.33769807 - samples/sec: 180.67 - lr: 0.100000\n",
      "2021-02-09 10:26:23,096 epoch 10 - iter 80/205 - loss 1.35071755 - samples/sec: 184.67 - lr: 0.100000\n",
      "2021-02-09 10:26:26,702 epoch 10 - iter 100/205 - loss 1.34103630 - samples/sec: 177.57 - lr: 0.100000\n",
      "2021-02-09 10:26:30,216 epoch 10 - iter 120/205 - loss 1.35452388 - samples/sec: 182.21 - lr: 0.100000\n",
      "2021-02-09 10:26:33,666 epoch 10 - iter 140/205 - loss 1.34891346 - samples/sec: 185.61 - lr: 0.100000\n",
      "2021-02-09 10:26:37,204 epoch 10 - iter 160/205 - loss 1.33893368 - samples/sec: 180.97 - lr: 0.100000\n",
      "2021-02-09 10:26:40,797 epoch 10 - iter 180/205 - loss 1.33699122 - samples/sec: 178.20 - lr: 0.100000\n",
      "2021-02-09 10:26:44,298 epoch 10 - iter 200/205 - loss 1.32827144 - samples/sec: 182.87 - lr: 0.100000\n",
      "2021-02-09 10:26:45,147 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:26:45,148 EPOCH 10 done: loss 1.3261 - lr 0.1000000\n",
      "2021-02-09 10:26:46,234 DEV : loss 1.1508471965789795 - score 0.6087\n",
      "2021-02-09 10:26:46,240 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:26:46,245 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:26:49,728 epoch 11 - iter 20/205 - loss 1.30205608 - samples/sec: 183.84 - lr: 0.100000\n",
      "2021-02-09 10:26:53,227 epoch 11 - iter 40/205 - loss 1.29058857 - samples/sec: 183.02 - lr: 0.100000\n",
      "2021-02-09 10:26:56,750 epoch 11 - iter 60/205 - loss 1.29203051 - samples/sec: 181.72 - lr: 0.100000\n",
      "2021-02-09 10:27:00,229 epoch 11 - iter 80/205 - loss 1.30087119 - samples/sec: 184.06 - lr: 0.100000\n",
      "2021-02-09 10:27:03,810 epoch 11 - iter 100/205 - loss 1.31608036 - samples/sec: 178.78 - lr: 0.100000\n",
      "2021-02-09 10:27:07,400 epoch 11 - iter 120/205 - loss 1.31576041 - samples/sec: 178.38 - lr: 0.100000\n",
      "2021-02-09 10:27:10,947 epoch 11 - iter 140/205 - loss 1.30410362 - samples/sec: 180.49 - lr: 0.100000\n",
      "2021-02-09 10:27:14,512 epoch 11 - iter 160/205 - loss 1.29479243 - samples/sec: 179.59 - lr: 0.100000\n",
      "2021-02-09 10:27:18,035 epoch 11 - iter 180/205 - loss 1.29747392 - samples/sec: 181.78 - lr: 0.100000\n",
      "2021-02-09 10:27:21,650 epoch 11 - iter 200/205 - loss 1.29178218 - samples/sec: 177.13 - lr: 0.100000\n",
      "2021-02-09 10:27:22,481 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:27:22,482 EPOCH 11 done: loss 1.2898 - lr 0.1000000\n",
      "2021-02-09 10:27:23,613 DEV : loss 1.1482964754104614 - score 0.6037\n",
      "2021-02-09 10:27:23,619 BAD EPOCHS (no improvement): 1\n",
      "2021-02-09 10:27:23,619 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:27:27,180 epoch 12 - iter 20/205 - loss 1.22232234 - samples/sec: 179.81 - lr: 0.100000\n",
      "2021-02-09 10:27:30,688 epoch 12 - iter 40/205 - loss 1.29060184 - samples/sec: 182.57 - lr: 0.100000\n",
      "2021-02-09 10:27:34,178 epoch 12 - iter 60/205 - loss 1.26610191 - samples/sec: 183.46 - lr: 0.100000\n",
      "2021-02-09 10:27:37,734 epoch 12 - iter 80/205 - loss 1.26264689 - samples/sec: 180.05 - lr: 0.100000\n",
      "2021-02-09 10:27:41,226 epoch 12 - iter 100/205 - loss 1.25686526 - samples/sec: 183.36 - lr: 0.100000\n",
      "2021-02-09 10:27:44,698 epoch 12 - iter 120/205 - loss 1.25101323 - samples/sec: 184.45 - lr: 0.100000\n",
      "2021-02-09 10:27:48,209 epoch 12 - iter 140/205 - loss 1.25751957 - samples/sec: 182.35 - lr: 0.100000\n",
      "2021-02-09 10:27:51,724 epoch 12 - iter 160/205 - loss 1.25163431 - samples/sec: 182.17 - lr: 0.100000\n",
      "2021-02-09 10:27:55,197 epoch 12 - iter 180/205 - loss 1.24853774 - samples/sec: 184.37 - lr: 0.100000\n",
      "2021-02-09 10:27:58,684 epoch 12 - iter 200/205 - loss 1.25726667 - samples/sec: 183.62 - lr: 0.100000\n",
      "2021-02-09 10:27:59,507 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:27:59,508 EPOCH 12 done: loss 1.2576 - lr 0.1000000\n",
      "2021-02-09 10:28:00,626 DEV : loss 1.101731538772583 - score 0.6211\n",
      "2021-02-09 10:28:00,632 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:28:00,637 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:28:04,180 epoch 13 - iter 20/205 - loss 1.18832186 - samples/sec: 180.74 - lr: 0.100000\n",
      "2021-02-09 10:28:07,790 epoch 13 - iter 40/205 - loss 1.19434992 - samples/sec: 177.33 - lr: 0.100000\n",
      "2021-02-09 10:28:11,357 epoch 13 - iter 60/205 - loss 1.22391306 - samples/sec: 179.54 - lr: 0.100000\n",
      "2021-02-09 10:28:14,934 epoch 13 - iter 80/205 - loss 1.22791045 - samples/sec: 179.00 - lr: 0.100000\n",
      "2021-02-09 10:28:18,519 epoch 13 - iter 100/205 - loss 1.22935363 - samples/sec: 178.59 - lr: 0.100000\n",
      "2021-02-09 10:28:22,003 epoch 13 - iter 120/205 - loss 1.23193780 - samples/sec: 183.80 - lr: 0.100000\n",
      "2021-02-09 10:28:25,503 epoch 13 - iter 140/205 - loss 1.23992618 - samples/sec: 182.92 - lr: 0.100000\n",
      "2021-02-09 10:28:29,014 epoch 13 - iter 160/205 - loss 1.24405103 - samples/sec: 182.39 - lr: 0.100000\n",
      "2021-02-09 10:28:32,578 epoch 13 - iter 180/205 - loss 1.24413582 - samples/sec: 179.66 - lr: 0.100000\n",
      "2021-02-09 10:28:36,163 epoch 13 - iter 200/205 - loss 1.24077895 - samples/sec: 178.61 - lr: 0.100000\n",
      "2021-02-09 10:28:36,941 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:28:36,941 EPOCH 13 done: loss 1.2385 - lr 0.1000000\n",
      "2021-02-09 10:28:38,061 DEV : loss 1.1134626865386963 - score 0.6158\n",
      "2021-02-09 10:28:38,067 BAD EPOCHS (no improvement): 1\n",
      "2021-02-09 10:28:38,068 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:28:41,517 epoch 14 - iter 20/205 - loss 1.23263430 - samples/sec: 185.62 - lr: 0.100000\n",
      "2021-02-09 10:28:45,039 epoch 14 - iter 40/205 - loss 1.23531346 - samples/sec: 181.78 - lr: 0.100000\n",
      "2021-02-09 10:28:48,504 epoch 14 - iter 60/205 - loss 1.21684365 - samples/sec: 184.80 - lr: 0.100000\n",
      "2021-02-09 10:28:52,066 epoch 14 - iter 80/205 - loss 1.22548942 - samples/sec: 179.76 - lr: 0.100000\n",
      "2021-02-09 10:28:55,601 epoch 14 - iter 100/205 - loss 1.24436851 - samples/sec: 181.14 - lr: 0.100000\n",
      "2021-02-09 10:28:59,127 epoch 14 - iter 120/205 - loss 1.21827631 - samples/sec: 181.62 - lr: 0.100000\n",
      "2021-02-09 10:29:02,683 epoch 14 - iter 140/205 - loss 1.21535973 - samples/sec: 180.03 - lr: 0.100000\n",
      "2021-02-09 10:29:06,231 epoch 14 - iter 160/205 - loss 1.21302405 - samples/sec: 180.46 - lr: 0.100000\n",
      "2021-02-09 10:29:09,723 epoch 14 - iter 180/205 - loss 1.21415321 - samples/sec: 183.34 - lr: 0.100000\n",
      "2021-02-09 10:29:13,240 epoch 14 - iter 200/205 - loss 1.21499070 - samples/sec: 182.04 - lr: 0.100000\n",
      "2021-02-09 10:29:14,052 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:29:14,052 EPOCH 14 done: loss 1.2145 - lr 0.1000000\n",
      "2021-02-09 10:29:15,136 DEV : loss 1.0786114931106567 - score 0.6315\n",
      "2021-02-09 10:29:15,142 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:29:15,146 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:29:18,708 epoch 15 - iter 20/205 - loss 1.16475783 - samples/sec: 179.80 - lr: 0.100000\n",
      "2021-02-09 10:29:22,176 epoch 15 - iter 40/205 - loss 1.19220333 - samples/sec: 184.64 - lr: 0.100000\n",
      "2021-02-09 10:29:25,881 epoch 15 - iter 60/205 - loss 1.19591459 - samples/sec: 172.81 - lr: 0.100000\n",
      "2021-02-09 10:29:29,418 epoch 15 - iter 80/205 - loss 1.20245995 - samples/sec: 181.00 - lr: 0.100000\n",
      "2021-02-09 10:29:33,027 epoch 15 - iter 100/205 - loss 1.20470702 - samples/sec: 177.44 - lr: 0.100000\n",
      "2021-02-09 10:29:36,485 epoch 15 - iter 120/205 - loss 1.20036115 - samples/sec: 185.18 - lr: 0.100000\n",
      "2021-02-09 10:29:40,028 epoch 15 - iter 140/205 - loss 1.19784093 - samples/sec: 180.68 - lr: 0.100000\n",
      "2021-02-09 10:29:43,630 epoch 15 - iter 160/205 - loss 1.19592132 - samples/sec: 177.79 - lr: 0.100000\n",
      "2021-02-09 10:29:47,131 epoch 15 - iter 180/205 - loss 1.20115276 - samples/sec: 182.85 - lr: 0.100000\n",
      "2021-02-09 10:29:50,706 epoch 15 - iter 200/205 - loss 1.20355420 - samples/sec: 179.12 - lr: 0.100000\n",
      "2021-02-09 10:29:51,496 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:29:51,497 EPOCH 15 done: loss 1.2027 - lr 0.1000000\n",
      "2021-02-09 10:29:52,638 DEV : loss 1.0688477754592896 - score 0.6439\n",
      "2021-02-09 10:29:52,644 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:29:52,649 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:29:56,200 epoch 16 - iter 20/205 - loss 1.27808926 - samples/sec: 180.28 - lr: 0.100000\n",
      "2021-02-09 10:29:59,766 epoch 16 - iter 40/205 - loss 1.23770861 - samples/sec: 179.59 - lr: 0.100000\n",
      "2021-02-09 10:30:03,390 epoch 16 - iter 60/205 - loss 1.23771710 - samples/sec: 176.66 - lr: 0.100000\n",
      "2021-02-09 10:30:06,937 epoch 16 - iter 80/205 - loss 1.20734431 - samples/sec: 180.51 - lr: 0.100000\n",
      "2021-02-09 10:30:10,536 epoch 16 - iter 100/205 - loss 1.19568300 - samples/sec: 177.89 - lr: 0.100000\n",
      "2021-02-09 10:30:14,022 epoch 16 - iter 120/205 - loss 1.19356185 - samples/sec: 183.72 - lr: 0.100000\n",
      "2021-02-09 10:30:17,576 epoch 16 - iter 140/205 - loss 1.19233268 - samples/sec: 180.12 - lr: 0.100000\n",
      "2021-02-09 10:30:21,159 epoch 16 - iter 160/205 - loss 1.19546859 - samples/sec: 178.74 - lr: 0.100000\n",
      "2021-02-09 10:30:24,582 epoch 16 - iter 180/205 - loss 1.19351303 - samples/sec: 187.06 - lr: 0.100000\n",
      "2021-02-09 10:30:28,194 epoch 16 - iter 200/205 - loss 1.18708009 - samples/sec: 177.25 - lr: 0.100000\n",
      "2021-02-09 10:30:28,992 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:30:28,992 EPOCH 16 done: loss 1.1880 - lr 0.1000000\n",
      "2021-02-09 10:30:30,103 DEV : loss 1.0659844875335693 - score 0.6383\n",
      "2021-02-09 10:30:30,109 BAD EPOCHS (no improvement): 1\n",
      "2021-02-09 10:30:30,110 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:30:33,548 epoch 17 - iter 20/205 - loss 1.20285867 - samples/sec: 186.26 - lr: 0.100000\n",
      "2021-02-09 10:30:37,119 epoch 17 - iter 40/205 - loss 1.20407065 - samples/sec: 179.28 - lr: 0.100000\n",
      "2021-02-09 10:30:40,702 epoch 17 - iter 60/205 - loss 1.19708813 - samples/sec: 178.74 - lr: 0.100000\n",
      "2021-02-09 10:30:44,279 epoch 17 - iter 80/205 - loss 1.18274250 - samples/sec: 179.23 - lr: 0.100000\n",
      "2021-02-09 10:30:47,863 epoch 17 - iter 100/205 - loss 1.16824023 - samples/sec: 178.61 - lr: 0.100000\n",
      "2021-02-09 10:30:51,340 epoch 17 - iter 120/205 - loss 1.18428904 - samples/sec: 184.18 - lr: 0.100000\n",
      "2021-02-09 10:30:54,936 epoch 17 - iter 140/205 - loss 1.19046017 - samples/sec: 178.06 - lr: 0.100000\n",
      "2021-02-09 10:30:58,473 epoch 17 - iter 160/205 - loss 1.18760255 - samples/sec: 181.01 - lr: 0.100000\n",
      "2021-02-09 10:31:02,058 epoch 17 - iter 180/205 - loss 1.18100794 - samples/sec: 178.62 - lr: 0.100000\n",
      "2021-02-09 10:31:05,621 epoch 17 - iter 200/205 - loss 1.18105752 - samples/sec: 179.71 - lr: 0.100000\n",
      "2021-02-09 10:31:06,451 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:31:06,452 EPOCH 17 done: loss 1.1834 - lr 0.1000000\n",
      "2021-02-09 10:31:07,584 DEV : loss 1.051302433013916 - score 0.6455\n",
      "2021-02-09 10:31:07,590 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:31:07,594 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:31:11,270 epoch 18 - iter 20/205 - loss 1.16719376 - samples/sec: 174.17 - lr: 0.100000\n",
      "2021-02-09 10:31:14,895 epoch 18 - iter 40/205 - loss 1.14047498 - samples/sec: 176.63 - lr: 0.100000\n",
      "2021-02-09 10:31:18,551 epoch 18 - iter 60/205 - loss 1.15374090 - samples/sec: 175.13 - lr: 0.100000\n",
      "2021-02-09 10:31:22,023 epoch 18 - iter 80/205 - loss 1.14550487 - samples/sec: 184.45 - lr: 0.100000\n",
      "2021-02-09 10:31:25,640 epoch 18 - iter 100/205 - loss 1.14499671 - samples/sec: 176.98 - lr: 0.100000\n",
      "2021-02-09 10:31:29,308 epoch 18 - iter 120/205 - loss 1.14721996 - samples/sec: 174.56 - lr: 0.100000\n",
      "2021-02-09 10:31:32,830 epoch 18 - iter 140/205 - loss 1.16077646 - samples/sec: 181.81 - lr: 0.100000\n",
      "2021-02-09 10:31:36,376 epoch 18 - iter 160/205 - loss 1.15398128 - samples/sec: 180.60 - lr: 0.100000\n",
      "2021-02-09 10:31:39,802 epoch 18 - iter 180/205 - loss 1.15687765 - samples/sec: 186.84 - lr: 0.100000\n",
      "2021-02-09 10:31:43,378 epoch 18 - iter 200/205 - loss 1.15794624 - samples/sec: 179.06 - lr: 0.100000\n",
      "2021-02-09 10:31:44,187 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:31:44,188 EPOCH 18 done: loss 1.1594 - lr 0.1000000\n",
      "2021-02-09 10:31:45,317 DEV : loss 1.053808331489563 - score 0.6344\n",
      "2021-02-09 10:31:45,323 BAD EPOCHS (no improvement): 1\n",
      "2021-02-09 10:31:45,323 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:31:48,734 epoch 19 - iter 20/205 - loss 1.14294230 - samples/sec: 187.72 - lr: 0.100000\n",
      "2021-02-09 10:31:52,335 epoch 19 - iter 40/205 - loss 1.14602855 - samples/sec: 177.86 - lr: 0.100000\n",
      "2021-02-09 10:31:55,976 epoch 19 - iter 60/205 - loss 1.15086315 - samples/sec: 175.83 - lr: 0.100000\n",
      "2021-02-09 10:31:59,417 epoch 19 - iter 80/205 - loss 1.14689609 - samples/sec: 186.09 - lr: 0.100000\n",
      "2021-02-09 10:32:03,067 epoch 19 - iter 100/205 - loss 1.14308884 - samples/sec: 175.43 - lr: 0.100000\n",
      "2021-02-09 10:32:06,649 epoch 19 - iter 120/205 - loss 1.13603554 - samples/sec: 178.75 - lr: 0.100000\n",
      "2021-02-09 10:32:10,150 epoch 19 - iter 140/205 - loss 1.14191992 - samples/sec: 182.85 - lr: 0.100000\n",
      "2021-02-09 10:32:13,781 epoch 19 - iter 160/205 - loss 1.15116968 - samples/sec: 176.36 - lr: 0.100000\n",
      "2021-02-09 10:32:17,425 epoch 19 - iter 180/205 - loss 1.14668663 - samples/sec: 175.69 - lr: 0.100000\n",
      "2021-02-09 10:32:21,012 epoch 19 - iter 200/205 - loss 1.14909996 - samples/sec: 178.52 - lr: 0.100000\n",
      "2021-02-09 10:32:21,812 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:32:21,813 EPOCH 19 done: loss 1.1518 - lr 0.1000000\n",
      "2021-02-09 10:32:22,934 DEV : loss 1.0084469318389893 - score 0.6455\n",
      "2021-02-09 10:32:22,943 BAD EPOCHS (no improvement): 2\n",
      "2021-02-09 10:32:22,944 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:32:26,327 epoch 20 - iter 20/205 - loss 1.06069073 - samples/sec: 189.30 - lr: 0.100000\n",
      "2021-02-09 10:32:29,812 epoch 20 - iter 40/205 - loss 1.09558512 - samples/sec: 183.68 - lr: 0.100000\n",
      "2021-02-09 10:32:33,348 epoch 20 - iter 60/205 - loss 1.10662985 - samples/sec: 181.12 - lr: 0.100000\n",
      "2021-02-09 10:32:36,863 epoch 20 - iter 80/205 - loss 1.11147159 - samples/sec: 182.16 - lr: 0.100000\n",
      "2021-02-09 10:32:40,498 epoch 20 - iter 100/205 - loss 1.11271072 - samples/sec: 176.11 - lr: 0.100000\n",
      "2021-02-09 10:32:44,047 epoch 20 - iter 120/205 - loss 1.10772752 - samples/sec: 180.43 - lr: 0.100000\n",
      "2021-02-09 10:32:47,533 epoch 20 - iter 140/205 - loss 1.10410571 - samples/sec: 183.69 - lr: 0.100000\n",
      "2021-02-09 10:32:50,985 epoch 20 - iter 160/205 - loss 1.10898066 - samples/sec: 185.47 - lr: 0.100000\n",
      "2021-02-09 10:32:54,581 epoch 20 - iter 180/205 - loss 1.12012778 - samples/sec: 178.06 - lr: 0.100000\n",
      "2021-02-09 10:32:58,112 epoch 20 - iter 200/205 - loss 1.11575108 - samples/sec: 181.34 - lr: 0.100000\n",
      "2021-02-09 10:32:58,959 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:32:58,960 EPOCH 20 done: loss 1.1193 - lr 0.1000000\n",
      "2021-02-09 10:33:00,069 DEV : loss 0.9856716394424438 - score 0.6635\n",
      "2021-02-09 10:33:00,074 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-09 10:33:00,084 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-09 10:33:00,085 Testing using best model ...\n",
      "2021-02-09 10:33:00,085 loading file models/baseline-charembeddings/best-model.pt\n",
      "2021-02-09 10:33:02,820 0.6206\t0.6212\t0.6209\n",
      "2021-02-09 10:33:02,821 \n",
      "Results:\n",
      "- F1-score (micro) 0.6209\n",
      "- F1-score (macro) 0.4970\n",
      "\n",
      "By class:\n",
      "BOOK       tp: 64 - fp: 92 - fn: 138 - precision: 0.4103 - recall: 0.3168 - f1-score: 0.3575\n",
      "COMPOSER   tp: 62 - fp: 38 - fn: 138 - precision: 0.6200 - recall: 0.3100 - f1-score: 0.4133\n",
      "FILM       tp: 44 - fp: 9 - fn: 192 - precision: 0.8302 - recall: 0.1864 - f1-score: 0.3045\n",
      "SINGER     tp: 688 - fp: 477 - fn: 144 - precision: 0.5906 - recall: 0.8269 - f1-score: 0.6890\n",
      "SONG       tp: 405 - fp: 156 - fn: 158 - precision: 0.7219 - recall: 0.7194 - f1-score: 0.7206\n",
      "2021-02-09 10:33:02,821 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "history = trainer.train(\n",
    "    './models/baseline-charembeddings',\n",
    "    learning_rate=0.1,\n",
    "    mini_batch_size=32,\n",
    "    max_epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
